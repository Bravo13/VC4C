Edge case behavior (OpenCL 1.2, page 325ff)

Unpack/Pack:
- use for type conversions (only works, if both unpack/pack are used, otherwise, e.g. negative numbers have no leading ones!)
- forces local to map to register-file A!
- use to support half??

Logging:
- consistent use of level (e.g. info for all passes, debug for details, error for all errors, ...)
 
Globals, Constants:
 - only write used globals to binary
 - __private memory is shared between all work-items, which it MUST NOT, need memory area per QPU! StackAllocations handle private memory correctly
 - __local memory is not reset (to initial values) after every work-group! Allowed to have initial value? If not, no extra work required
 - __global memory is handled correctly: initialized once (by copying the data into the buffer) and persistent through all work-groups
 - __constant memory is handled correctly, since it is never overwritten
 
Answer questions:
- Two set-flags (with inverted conditions) in same instruction. Is flags of MUL set?
- Can unpack from VPM/TMU? (If so, only when read from reg-file A) 
 
Support additional data types:
- cl_khr_fp16:
  - Internally calculate with float
  - Map all std-functions to float
  - on load/store (half-parameter are allowed even without this extension?), use un-/pack modes
 
New optimization steps:
- split long-living locals, which are written just once ??
  - copy into new local at the begin of every basic block, they are used
  - use the new local with that basic block
  -> can improve register-assignment
  (- place copy in a way, that it can be (most likely) combined with another instruction, so it doesn't require any additional instructions)
  - add before reordering
- add nops into VPM access (see: https://www.raspberrypi.org/forums/viewtopic.php?p=1143940#p1095422)
  - compare clpeak global_bandwidth current with (2 * nrows + 6) nops between writing vpm_load_addr and vpm_load_wait (more exact: 2 for scalar values, 5 for 16-element vectors)
  - compare clpeak global_bandwidth current with (2 * nrows + 10) nops between vpm_store_addr and vpm_store_wait (more exact: 2 for scalar values, 3.5 for 16-element vectors)
  - compare clpeak global_bandwidth current with (5) nops between vpm_load_setup and first vpm_read
  - writing vpm does not add any additional stall
  - compare clpeak global_bandwidth current with all of the added nops
- rewrite short if-else (without side-effects)
  - calculate both branches in any case into temporaries
  - in the end determine which value to use

VPM:
- add handling of local/global offset/size to optimization combining VPM access. how? (e.g. ./testing/test_work_item.cl)
- use VPM as cache:
  find blocks of memory (how to determine their size??) read from/written to at several places
  divide VPM to reserve a small portion for other read/writes, the remainder use as cache for this blocks of memory
  if read access: read block once into VPM, then read from VPM
  if write access: write to VPM and write once into memory
  !!QPUs share the VPM, so access still critical section, also only need to read/write from/to RAM in one QPU
- reserve area in VPM for spilling locals (not into memory, but into VPM)
  need to reserve extra area per QPU
  how to efficiently determine locals with a huge usage-range with gaps??
  in Graph Coloring (or as an optimization step), spill locals where there is a big gap (heed branches!!) between two/or more "blocks" of uses
  split those locals into "before spilling" and "after spilling" for easier/correct coloring
- move global/local data into VPM??
  pros: faster loading
  cons: fill up VPM, what to do if doesn't fit
- if memory access optimization can handle RAM <-> VPM and VPM <-> QPU separately, implement prefetch() by loading into VPM
  need to heed VPM areas as well as synchronization
  only useful if optimizer detects, that this specific area is currently cached in VPM
- don't use fixed areas for fixed purposes, but track ranges (life-times) where how much of the VPM is used for what
  similar to register-mapping (but much simpler), map ranges to VPM areas at the end of compilation, by setting the VPM offset
  what to do if the VPM is full? Need to check enough free space for range before allocating it!
  need to distinguish per-QPU usage (e.g. spilled locals) and common usage (I/O cache) and need to e.g. reserve 12-times the space for per-QPU usage and map QPU-index to correct offset
  pros: better utilization of VPM
  
Image support:
- use TMU for loading images:
  automatically reads UNIFORMS containing the texture config (width, height, type, border wrap mode/border color) on initiating texture read (Broadcom specification page 40+)
  could use the register to set the uniform pointer before initiating texture reads to point to an arbitrary buffer (e.g. in global data, extra segment) to read texture-info from (for the correct image)
    how to get the correct texture base-pointer (run-time!) into the UNIFORM? would need to modify the data-location
    or write texture-setup values host-side (when setting image as parameter), since we there know the real width/height, pixel-type as well as base-address
    need to re-set the UNIFORM pointer at least once before running the next work-group iteration to the original value (passed via UNIFORM)
  could use "2D child-images" for image arrays
  texture coordinates: s, t = u,v = x,y. r is border color (coordinate, wrapping mode or color-value?), defaults to 0. "not used for normal 2D texturing" (page 44). b is LOD lookup bias
  texture coordinate s needs to be written last, triggers the read. coordinates not written default to zero
  supports image formats (table 18): RGBA8888 (8-bit RGBA), RGBX8888 (8-bit RGB, A=1.0), RGBA4444 (4-bit RGBA), RGBA5551 (5-bit RGB, 1-bit A), RGB565 (A=1.0), 
    LUMINANCE (8-bit luminance, A=1.0), ALPHA (8-bit A, RGB=0), LUMALPHA (8-bit luminance, 8-bit A), ETC1 (Ericsson Texture Compression format),
    S16F (16-bit float, with interpolation), S8 (8-bit integer, with interpolation), S16 (16-bit integer, without interpolation), BW (1-bit black/white),
    A4 (4-bit A), A1 (1-bit A), RGBA64 (16-bit float per channel RGBA), RGBA32R (8-bit per channel RGBA, raster format), YUYV422R (8-bit per channel YUYV, raster format)
    -> see also OpenGL-ES 1.x and 2.0 texture modes and formats specifications for meaning of modes
  supports basic interpolation (for some types), see table 19
  writing to s-coordinate triggers texture read (incl. wrapping, interpolation, correct type) at given coordinates s, t [0, 1] into register r4
    can use pack-modes to convert into requested data-type??
    write to s-coordinate cannot be conditional write, TMU is always triggered, may have undefined data (see Addendum)
    writing 16 (SIMD!) different addresses to TMU_S loads values from 16 different locations? (see http://www.aholme.co.uk/GPU_FFT/Main.htm#Parallelism)
  modes (Broadcom spec page 44): 
    2D texture mode: s, t are float coords [0, 1], clamped according to wrap mode -> provides x, y coords in texture, r unused, bias (b?) added to parameter, if set
    cube map mode: relevant?
    child image: need to set offset of currently used child image into the UNIFORM being loaded
  automatic TMU swapping -> all writes to TMU0
  slice shares 1/2 TMUs -> mutex required?
  TMU has request FIFO with 8 (according to Addendum only 4 stable) entries (per slice? per QPU?)
  texture memory layouts, see Broadcom specification, pages 105+
  since TMU read always blocks 9 to 20 instructions, could add optimization, which reorders instructions between loadtmu and read of r4
  3D images supported? via cube map image? or child images?
- tile buffer (Broadcom spec, pages 46+): 
  what use does it have?
- relevant HW errata: HW-2619, HW-2645, HW-2753

Fix register conflicts:
- case 1: inserting NOP to fix seems appropriate for now
- case 2: problem: B blocked by small immediate
  -> load all immediate values separately use register (accumulator) value? puts strain on accumulators
  -> for every use with immediate, copy local (if range greater then accumulator range) before use, use temporary with immediate? ->done
- case 3: ??

Literal values:
- make clear where Literal is used and where SmallImmediate:
  - currently: up to handleImmediates, everything (except vector-rotations) are Literal, after this optimization step, everything (except load-instructions) is SmallImmediate
  - how to make explicit?
- remove Literal completely from Value?
  - by default, in front-ends, on constants, insert load to load literal value (except vector-rotations, 0 and boolean values)
  - revert optimization steps (handleContainer?, handleImmediate, handleUseWithImmediate) to in-line literals only into operations when they can be converted to small immediate, 
    also check usage-range of other parameters of operation to make handleUseWithImmediate obsolete
  - need extra case for global values/memory access indices, since they can have 32-bit literals, not just small immediates
  - need to rewrite/rethink containers, could have non-scalar constant values? e.g. constant array of structs?
    - containers can contain an "undefined" value, need some representation of undefined for Literal/ContainerValue
    - containers are used in global values (e.g. constants, initializers) and masks for vector-shuffle
    - containers in globals can contain non-literals (e.g. constant vectors as part of a constant array), maybe even constant values of struct/array types (e.g. array of structs?)
    - containers for masks (for insertVectorShuffle) are mostly literals (SPIR-V OpVectorShuffle, LLVM-IR shufflevector and image-dimension extraction), only the SPIR-V implementation of shuffle2 uses an arbitrary Value, 
      but insertVectorShuffle only handles undefined or literal values
    -> globals could be converted to Global with ContainerValue instead of Value as initial value, with Literal and ContainerValue as children 
       (or ContainerValue gets DataType, flag whether undefined, Optional<Literal> and vector<ContainerValue>, rename to LiteralContainer/CompositeLiteral)
    -> literal containers for shuffle-masks could be handled similar to globals
    -> how to handle non-literal shuffle-masks? Extra function? Need anyway, since we currently only handle undefined/literal indices
    -> how to handle reading of ContainerValues? For SPIR-V, SpvOpConstantComposite could be used for global data and e.g. constant vectors somewhere in code. 
       For LLVM-IR, if Value has no more containers, need to copy parseValue for globals/literal containers
  
calculation:
- make sure, all calculations are done with 32-bit types in mind (int, float)
  - need to sign/zero-extend short/char to int, so calculations are correct
  - e.g. -32 -11 is correct for integer, but not short, since it is loaded without extension from VPM
  - writing to VPM is automatically truncated, seems correct, since short -32 = int -32 & 0xFFFF
  - need to check/modify all arithmetic operators / integer functions whether they handle e.g. short-calculations on integers correctly (i.e. not truncating away signs, etc.)
  - how to determine whether to zero- or sign-extend values read from VPM?? SPIR-V gives us no information about the signedness 
    (2.16.3: "Validation Rules for Kernel Capabilities: The Signedness in OpTypeInt must always be 0.")
- or: run arithmetic calculations with correct type
  - need to make sure, results are correct, e.g. sub (short) 0xFBCD, 0x0010 yields different results when signed/unsigned?!
  - need to make sure, flags are set correctly (esp. negative, since it probably checks for 31th bit, not the MSB of the real type, which the ALU doesn't know!)

Check for vc4/v3d drivers:
   
- DRM driver (https://github.com/raspberrypi/linux/blob/rpi-4.19.y/include/uapi/drm/vc4_drm.h)
  - also ioctls for reserving/mmapping buffers, reading some parameters
  - performance counters (https://github.com/raspberrypi/linux/blob/rpi-4.19.y/drivers/gpu/drm/vc4/vc4_perfmon.c)
    -> only meaningful with DRM executions (shaders), which cannot be used to access VPM DMA

- vc-mem (https://github.com/raspberrypi/linux/blob/rpi-4.19.y/drivers/char/broadcom/vc_mem.c)
  - mmap as user?
  - mmap reserves memory?
  - mmap memory read/writeable from QPUs and host?
- vc4 (https://github.com/raspberrypi/linux/blob/rpi-4.19.y/drivers/gpu/drm/vc4/vc4_drv.c)
  - ioctls return values
  - control via libDRM user-space library
  - https://www.kernel.org/doc/html/latest/gpu/drm-uapi.html
  - test access, device is /dev/fb0, /dev/dri/cardX /dev/dri/renderD?!
- vcsm (https://github.com/raspberrypi/linux/blob/rpi-4.19.y/drivers/char/broadcom/vc_sm/vmcs_sm.c, https://github.com/raspberrypi/linux/blob/rpi-4.19.y/include/linux/broadcom/vmcs_sm_ioctl.h)
  - communicates via VCHI kernel internal service (that also all the camera/audio/etc. drivers use)
    VCHI runs in extra kernel thread, allows to wait/not wait for result, VCSM is always synchronous
  - difference to vc-mem? or vcio?
  - seems interoperable with mailbox (handles)
  - automatically cleans up memory resources when closing handle to device file
  - unlocking buffer what happens exactly? Lose data or buffer just moved as-is?
  - statistics/debug info can be queried with /opt/.../vcsmem
    -> is dumped to kernel log -> dmesg
  - also some information via debugfs at /sys/kernel/debug/vc-smem
  - compare to mailbox
    - features (e.g. caching, debug info, etc.)
    - performance
  user-space library as wrapper around ioctls (https://github.com/raspberrypi/userland/blob/master/host_applications/linux/libs/sm/user-vcsm.h)
  -> see also examples (brcmjpeg_test, vcsm_square)
  
  -> overhaul memory management using VCSM?
  - only set cache/access where needed, e.g. no need to map local buffer into host user space
  - only lock while actually required (see vcsm_malloc_cache documentation), e.g. while accessing? -> lock while clEnqueueMapBuffer'd
    -> need to re-query GPU-side address too for next lock!
    -> need to track status (locked + address vs. unlocked)

printf support:
- kernel add uniform metadata flag that printf is used
- if printf flag set, reserve buffer on host (see CL_DEVICE_PRINTF_BUFFER_SIZE and minimum)
- kernel copy format string and args to buffer
  - store #bytes + value for every argument?
- kernel keeps track of current offset from printf buffer (e.g. stored as first word of printf buffer)
- after execution, if printf flag set, call printf on host, pass host-pointer to copied arguments
  - use #bytes to increment pointer
  - how to call printf with dynamic arguments?? -> need to fake/create own implementation?!

Memory reduction:
- Test candidates: clpeak/float (~31MB), integer tests (~155MB), hashcat(VC4CL#81, hashcat -m 1000 -a 3 hash.txt -w 4 -O with hash.txt is 414A99E86FB3E6812AA8A1C782B9F87C ~990MB)
- Interference graph (esp. for integer test) > 50MB
- Graph coloring (esp. for hashcat) > 60MB
  -> Flatten graph adjacency sets/maps?
     - Sorted vector adjacency list results in ~10% RAM saving, duplicates execution time for clpeak int
- Liveness analysis (esp. for hashcat) > 250MB
- Instructions
  -> Make operands to SmallVector?
     - Only needs more than 2 operands (or maybe 3 for operation + move) for function call anyway...
     - Have inline array of 2 Values
     - Have virtual function to retrieve index 2 - N, only implement where needed
     - Check first where all the arguments are needed at all (e.g. getArguments())
     - Write custom iterator type?
- Also test performance/speed and check for regression
- rerun sanitizers, all tests!
